{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62eb3a3-a712-4f8c-a5dc-e78047416436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/Projects/NaturalHistoryMuseum/ADEPT/ADEPT/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, Token\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from pathlib import Path\n",
    "from spacy.util import filter_spans\n",
    "from adept.components.registry import ComponentsRegistry\n",
    "from adept.preprocess import Preprocess\n",
    "from adept.postprocess import Postproccess\n",
    "from adept.config import TRAINING_DIR\n",
    "from adept.traits import Traits\n",
    "from adept.fields import Fields\n",
    "from adept.utils.helpers import token_get_ent\n",
    "\n",
    "from adept.utils.expand import ExpandSpan\n",
    "from adept.tasks.patterns.trait import TraitPatternsTask   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1bb01c-0fb5-40d4-9e3f-11eae67234d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(TRAINING_DIR / 'adept')\n",
    "\n",
    "preprocess = Preprocess() \n",
    "preprocess = Preprocess() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b812cfe-a760-40d5-a4c6-1ec60fc723d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transformer',\n",
       "  <spacy_transformers.pipeline_component.Transformer at 0x13be14d00>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x13bb9c6d0>),\n",
       " ('sentencizer',\n",
       "  <adept.components.sentencizer.SentencizerComponent at 0x13bdb7820>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x13be149a0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x13bb9c7b0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x13be26580>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x13be07b40>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba817b1-99fb-427c-b781-273474b37101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9894326-c26f-4468-b7c4-3c9892398687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cardinal_ents = [e for e in doc.ents if e.label_ == 'CARDINAL']\n",
    "\n",
    "  \n",
    "# # We use the dependency parse to find nummod noun, that's also an entity     \n",
    "# for cardinal_ent in cardinal_ents:\n",
    "    \n",
    "#     print(cardinal_ent)\n",
    "#     print(cardinal_ent.sent)\n",
    "#     # root = cardinal_ent.root\n",
    "#     # print(root)\n",
    "#     # ent = token_get_ent(root.head, ['PART', 'TRAIT'])     \n",
    "#     # print(ent)\n",
    "    \n",
    "    \n",
    "# token = cardinal_ent.sent[12]\n",
    "\n",
    "# next_token = doc[token.i + 1]    \n",
    "\n",
    "# next_token.shape_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b51ff5a-dbb7-4c56-a2f9-cccc87e641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencizerComponent:\n",
    "    \n",
    "    \"\"\"\n",
    "    Sentencizer, to split sentences on semicolons and periods.\n",
    "    \n",
    "    If we just add is_sent_start for each semicolon, the default\n",
    "    parser will split incorrectly\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nlp: Language):\n",
    "        self.nlp = nlp\n",
    "    \n",
    "    def __call__(self, doc):        \n",
    "        for token in doc[:-1]:\n",
    "            next_token = doc[token.i + 1]\n",
    "            if self._is_semicolon(doc, token):\n",
    "                next_token.is_sent_start = True\n",
    "            elif self._is_period(doc, token):\n",
    "                # period then capital: new sentence                 \n",
    "                if next_token.shape_.startswith('X'):\n",
    "                    next_token.is_sent_start = True\n",
    "                # period then number: possibly new sentence. let the default parse evaluate it    \n",
    "                elif next_token.shape_.startswith('d'):\n",
    "                    next_token.is_sent_start = None\n",
    "                else:\n",
    "                    next_token.is_sent_start = False\n",
    "            else:\n",
    "                next_token.is_sent_start = False\n",
    "\n",
    "                \n",
    "        return doc\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_semicolon(doc, token):\n",
    "        return token.text == \";\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_period(doc, token):            \n",
    "        return token.text == \".\"  \n",
    "    \n",
    "    \n",
    "    \n",
    "# sent = SentencizerComponent(nlp)\n",
    "# sent(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90461554-31a8-4562-9613-ecbe615f8440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SentencizerComponent at 0x104286e30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.factory(\"sent\")\n",
    "def create_discrete_traits_component(nlp: Language, name: str):\n",
    "    return SentencizerComponent(nlp)\n",
    "\n",
    "\n",
    "nlp.replace_pipe(\"sentencizer\", \"sent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09f2754-2f35-48b1-96d9-1479183065c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOT\n",
      "dd\n",
      "NONE\n",
      "DOT\n",
      "Xxxx\n"
     ]
    }
   ],
   "source": [
    "text = \"Herbs to 40-100.4 cm tall, annual, much branched; 2 ovaries. 56 stamenoids. Seed volume is about 2 cm³. 2n=23,34\"  \n",
    "\n",
    "doc = nlp(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6d87c67-ad1d-428a-9aa5-e97571067fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herbs to 40-100.4 cm tall, annual, much branched;\n",
      "--\n",
      "2 ovaries.\n",
      "--\n",
      "56 stamenoids.\n",
      "--\n",
      "Seed volume is about 2 cm³. 2n=23,34\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfddc1f-bc3a-4525-9689-d06eb15907fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADEPT",
   "language": "python",
   "name": "adept"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
