[paths]
trained_model = null
trf_model = null

[system]
gpu_allocator = "pytorch"
seed = 0

[nlp]
lang = "en"
pipeline = ["sentencizer", "transformer", "ner", "tagger", "parser", "attribute_ruler", "lemmatizer"]
batch_size = 2
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}

[components]

[components.transformer]
source = ${paths.trained_model}

[components.ner]
source = ${paths.trained_model}

[components.sentencizer]
source = ${transformer_model}

[components.tagger]
source = ${transformer_model}

[components.parser]
source = ${transformer_model}

[components.attribute_ruler]
source = ${paths.trained_model}

[components.lemmatizer]
source = ${paths.trained_model}

